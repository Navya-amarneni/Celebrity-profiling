{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "csvfile = open('labels.csv', 'r',encoding = \"utf8\")\n",
    "jsonfile = open('lab.json', 'w')\n",
    "\n",
    "fieldnames = (\"id\",\"occupation\",\"gender\",\"fame\",\"birthyear\")\n",
    "reader = csv.DictReader( csvfile, fieldnames)\n",
    "out = json.dumps( [ row for row in reader ] )\n",
    "jsonfile.write(out)\n",
    "            \n",
    "            \n",
    "\n",
    "csvfile = open('feed.csv', 'r',encoding = \"utf8\")\n",
    "jsonfile = open('cel.json', 'w')\n",
    "\n",
    "fieldnames = (\"id\",\"text\")\n",
    "reader = csv.DictReader( csvfile, fieldnames)\n",
    "out = json.dumps( [ row for row in reader ] )\n",
    "jsonfile.write(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('cel.json',encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "tweets=data\n",
    "\n",
    "\n",
    "with open('lab.json',encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data1 = json.loads(line)\n",
    "labels=data1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_feed(tweet: str):\n",
    " \n",
    "    t = tweet.lower()\n",
    "    t = re.sub(url_re, \" <URL> \", t)\n",
    "    t = t.replace(\"\\n\", \"\")\n",
    "    t = t.replace(\"#\", \" <HASHTAG> \")\n",
    "    t = re.sub(mention_re, \" <USER> \", t)\n",
    "    t = re.sub(smile_re, \" <EMOTICON> \", t)\n",
    "    t = re.sub(emoji_re, \" <EMOJI> \", t)\n",
    "    t = re.sub(time_re, \" <TIME> \", t)\n",
    "    t = re.sub(numbers_re, \" <NUMBER> \", t)\n",
    "    t = re.sub(not_ascii_re, \"\", t)\n",
    "    t = re.sub(space_collapse_re, \" \", t)\n",
    "    t = t.strip()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "def untokenize(words):\n",
    "    \"\"\"Untokenizing a text undoes the tokenizing operation, restoring\n",
    "    punctuation and spaces to the places that people expect them to be.\n",
    "    Ideally, `untokenize(tokenize(text))` should be identical to `text`,\n",
    "    except for line breaks.\n",
    "    \"\"\"\n",
    "    text = ' '.join(words)\n",
    "    step1 = text.replace(\"`` \", '\"').replace(\" ''\", '\"').replace('. . .', '...')\n",
    "    step2 = step1.replace(\" ( \", \" (\").replace(\" ) \", \") \")\n",
    "    step3 = re.sub(r' ([.,:;?!%]+)([ \\'\"`])', r\"\\1\\2\", step2)\n",
    "    step4 = re.sub(r' ([.,:;?!%]+)$', r\"\\1\", step3)\n",
    "    step5 = step4.replace(\" '\", \"'\").replace(\" n't\", \"n't\").replace(\n",
    "        \"can not\", \"cannot\")\n",
    "    step6 = step5.replace(\" ` \", \" '\")\n",
    "    return step6.strip()\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/a/47091490\n",
    "def decontracted(phrase):\n",
    "    \"\"\"Convert contractions like \"can't\" into \"can not\"\n",
    "    \"\"\"\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    #phrase = re.sub(r\"n't\", \" not\", phrase) # resulted in \"ca not\" when sentence started with \"can't\"\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "\n",
    "# https://github.com/rishabhverma17/sms_slang_translator/blob/master/slang.txt\n",
    "slang_abbrev_dict = {\n",
    "    'AFAIK': 'As Far As I Know',\n",
    "    'AFK': 'Away From Keyboard',\n",
    "    'ASAP': 'As Soon As Possible',\n",
    "    'ATK': 'At The Keyboard',\n",
    "    'ATM': 'At The Moment',\n",
    "    'A3': 'Anytime, Anywhere, Anyplace',\n",
    "    'BAK': 'Back At Keyboard',\n",
    "    'BBL': 'Be Back Later',\n",
    "    'BBS': 'Be Back Soon',\n",
    "    'BFN': 'Bye For Now',\n",
    "    'B4N': 'Bye For Now',\n",
    "    'BRB': 'Be Right Back',\n",
    "    'BRT': 'Be Right There',\n",
    "    'BTW': 'By The Way',\n",
    "    'B4': 'Before',\n",
    "    'B4N': 'Bye For Now',\n",
    "    'CU': 'See You',\n",
    "    'CUL8R': 'See You Later',\n",
    "    'CYA': 'See You',\n",
    "    'FAQ': 'Frequently Asked Questions',\n",
    "    'FC': 'Fingers Crossed',\n",
    "    'FWIW': 'For What It\\'s Worth',\n",
    "    'FYI': 'For Your Information',\n",
    "    'GAL': 'Get A Life',\n",
    "    'GG': 'Good Game',\n",
    "    'GN': 'Good Night',\n",
    "    'GMTA': 'Great Minds Think Alike',\n",
    "    'GR8': 'Great!',\n",
    "    'G9': 'Genius',\n",
    "    'IC': 'I See',\n",
    "    'ICQ': 'I Seek you',\n",
    "    'ILU': 'I Love You',\n",
    "    'IMHO': 'In My Humble Opinion',\n",
    "    'IMO': 'In My Opinion',\n",
    "    'IOW': 'In Other Words',\n",
    "    'IRL': 'In Real Life',\n",
    "    'KISS': 'Keep It Simple, Stupid',\n",
    "    'LDR': 'Long Distance Relationship',\n",
    "    'LMAO': 'Laugh My Ass Off',\n",
    "    'LOL': 'Laughing Out Loud',\n",
    "    'LTNS': 'Long Time No See',\n",
    "    'L8R': 'Later',\n",
    "    'MTE': 'My Thoughts Exactly',\n",
    "    'M8': 'Mate',\n",
    "    'NRN': 'No Reply Necessary',\n",
    "    'OIC': 'Oh I See',\n",
    "    'OMG': 'Oh My God',\n",
    "    'PITA': 'Pain In The Ass',\n",
    "    'PRT': 'Party',\n",
    "    'PRW': 'Parents Are Watching',\n",
    "    'QPSA?': 'Que Pasa?',\n",
    "    'ROFL': 'Rolling On The Floor Laughing',\n",
    "    'ROFLOL': 'Rolling On The Floor Laughing Out Loud',\n",
    "    'ROTFLMAO': 'Rolling On The Floor Laughing My Ass Off',\n",
    "    'SK8': 'Skate',\n",
    "    'STATS': 'Your sex and age',\n",
    "    'ASL': 'Age, Sex, Location',\n",
    "    'THX': 'Thank You',\n",
    "    'TTFN': 'Ta-Ta For Now!',\n",
    "    'TTYL': 'Talk To You Later',\n",
    "    'U': 'You',\n",
    "    'U2': 'You Too',\n",
    "    'U4E': 'Yours For Ever',\n",
    "    'WB': 'Welcome Back',\n",
    "    'WTF': 'What The Fuck',\n",
    "    'WTG': 'Way To Go!',\n",
    "    'WUF': 'Where Are You From?',\n",
    "    'W8': 'Wait',\n",
    "    '7K': 'Sick:-D Laugher'\n",
    "}\n",
    "\n",
    "\n",
    "def unslang(text):\n",
    "    \"\"\"Converts text like \"OMG\" into \"Oh my God\"\n",
    "    \"\"\"\n",
    "    if text.upper() in slang_abbrev_dict.keys():\n",
    "        return slang_abbrev_dict[text.upper()]\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "\n",
    "\n",
    "# Reference : https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
    "\n",
    "\n",
    "def replace_urls(text):\n",
    "    text=re.sub(r\"http\\S+\", 'URL', text)\n",
    "    text=re.sub(r\"www\\S+\", 'URL', text)\n",
    "    text=re.sub(r\"pic.twitter.com\\S+\", 'URL', text)\n",
    "    text=re.sub(r'https.*[^ ]', 'URL',text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def clean(reg_exp, text):\n",
    "    text = re.sub(reg_exp, \" \", text)\n",
    "\n",
    "    # replace multiple spaces with one.\n",
    "    text = re.sub('\\s{2,}', ' ', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text()\n",
    "    return stripped_text\n",
    "\n",
    "def clean_all(t):\n",
    "    \n",
    "    # first do bulk cleanup on tokens that don't depend on word tokenization\n",
    "\n",
    "    # remove xml tags\n",
    "    t = clean(r\"<[^>]+>\", str(t))\n",
    "    t = clean(r\"&lt;\", str(t))\n",
    "    t = clean(r\"&gt;\", str(t))\n",
    "\n",
    "    # remove URLs\n",
    "    t = replace_urls(t)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Removing HTML tags\n",
    "    t=strip_html_tags(t)\n",
    "    \n",
    "    #remove_accented_chars\n",
    "    t=remove_accented_chars(t)\n",
    "\n",
    "    # https://stackoverflow.com/a/35041925\n",
    "    # replace multiple punctuation with single. Ex: !?!?!? would become ?\n",
    "    t = clean(r'[\\?\\.\\!]+(?=[\\?\\.\\!])', t)\n",
    "\n",
    "    \n",
    "\n",
    "    # expand common contractions like \"I'm\" \"he'll\"\n",
    "    t = decontracted(t)\n",
    "\n",
    "    # now remove/expand bad patterns per word\n",
    "    words = word_tokenize(t)\n",
    "\n",
    "    clean_words = []\n",
    "\n",
    "    for w in words:\n",
    "        # normalize punctuation\n",
    "        w = re.sub(r'&', 'and', w)\n",
    "\n",
    "        # expand slang like OMG = Oh my God\n",
    "        w = unslang(w)\n",
    "\n",
    "\n",
    "        clean_words.append(w)\n",
    "\n",
    "    # join the words back into a full string\n",
    "    t = untokenize(clean_words)\n",
    "\n",
    "\n",
    "    # finally, remove any non ascii and special characters that made it through\n",
    "    t = clean(r\"[^A-Za-z0-9\\.\\'!\\?,\\$]\", t)\n",
    "\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet=[]\n",
    "birthyear=[]\n",
    "gender=[]\n",
    "occupation=[]\n",
    "ids=[]\n",
    "fame=[]\n",
    "for i in range(len(tweets)):\n",
    "    if i!=0:\n",
    "        tweet.append(clean_all(tweets[i][\"text\"]))\n",
    "        birthyear.append(labels[i]['birthyear'])\n",
    "        gender.append(labels[i]['gender'])\n",
    "        occupation.append(labels[i]['occupation'])\n",
    "        ids.append(labels[i]['id'])\n",
    "        fame.append(labels[i]['fame'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from zipfile import ZipFile\n",
    "import json\n",
    "\n",
    "celebrity = {\n",
    "    'id':ids,\n",
    "    'text': tweet,\n",
    "        'birthyear': birthyear,\n",
    "         'gender':gender,\n",
    "           'occupation':occupation,\n",
    "    'fame':fame\n",
    "        }\n",
    "\n",
    "\n",
    "df = pd.DataFrame(celebrity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>birthyear</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>fame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22704</td>\n",
       "      <td>Back at it with looking for .her Circa early 2...</td>\n",
       "      <td>C</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>superstar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46305</td>\n",
       "      <td>The last presidential election turned on fewer...</td>\n",
       "      <td>D</td>\n",
       "      <td>male</td>\n",
       "      <td>politics</td>\n",
       "      <td>superstar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30260</td>\n",
       "      <td>Angels obbieWilliams t.co A6rx5WA0ieAmazing Th...</td>\n",
       "      <td>B</td>\n",
       "      <td>female</td>\n",
       "      <td>performer</td>\n",
       "      <td>superstar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4874</td>\n",
       "      <td>Listen to Shallow, Always Remember Us This Way...</td>\n",
       "      <td>B</td>\n",
       "      <td>female</td>\n",
       "      <td>creator</td>\n",
       "      <td>superstar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41392</td>\n",
       "      <td>So happy for my island! Vote for Madeira, for ...</td>\n",
       "      <td>B</td>\n",
       "      <td>male</td>\n",
       "      <td>manager</td>\n",
       "      <td>superstar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text birthyear  gender  \\\n",
       "0  22704  Back at it with looking for .her Circa early 2...         C  female   \n",
       "1  46305  The last presidential election turned on fewer...         D    male   \n",
       "2  30260  Angels obbieWilliams t.co A6rx5WA0ieAmazing Th...         B  female   \n",
       "3   4874  Listen to Shallow, Always Remember Us This Way...         B  female   \n",
       "4  41392  So happy for my island! Vote for Madeira, for ...         B    male   \n",
       "\n",
       "  occupation       fame  \n",
       "0  performer  superstar  \n",
       "1   politics  superstar  \n",
       "2  performer  superstar  \n",
       "3    creator  superstar  \n",
       "4    manager  superstar  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"celebrity_datas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
